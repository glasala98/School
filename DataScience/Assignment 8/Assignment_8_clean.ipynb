{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extreme-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can import *ANYTHING* you want here.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error # Requires sklearn 0.24 (December 2020), update with conda/pip if needed.\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import OrderedDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-parker",
   "metadata": {},
   "source": [
    "# Assignment 8: Tree methods\n",
    "\n",
    "In this assignment we'll study tree methods and their capabilities as interpolators and extrapolators, and the importance of understanding your data. We will use a dataset of energy consumption of home appliances for houses in Chievres, Belgium. The data has the following variables:\n",
    "\n",
    "- date time year-month-day hour:minute:second\n",
    "- Appliances, energy use in Wh (**Target variable**)energy_extrapolation\n",
    "- lights, energy use of light fixtures in the house in Wh\n",
    "- T1, Temperature in kitchen area, in Celsius\n",
    "- RH_1, Humidity in kitchen area, in %\n",
    "- T2, Temperature in living room area, in Celsius\n",
    "- RH_2, Humidity in living room area, in %\n",
    "- T3, Temperature in laundry room area\n",
    "- RH_3, Humidity in laundry room area, in %\n",
    "- T4, Temperature in office room, in Celsius\n",
    "- RH_4, Humidity in office room, in %\n",
    "- T5, Temperature in bathroom, in Celsius\n",
    "- RH_5, Humidity in bathroom, in %\n",
    "- T6, Temperature outside the building (north side), in Celsius\n",
    "- RH_6, Humidity outside the building (north side), in %\n",
    "- T7, Temperature in ironing room , in Celsius\n",
    "- RH_7, Humidity in ironing room, in %\n",
    "- T8, Temperature in teenager room 2, in Celsius\n",
    "- RH_8, Humidity in teenager room 2, in %\n",
    "- T9, Temperature in parents room, in Celsius\n",
    "- RH_9, Humidity in parents room, in %\n",
    "- To, Temperature outside (from Chievres weather station), in Celsius\n",
    "- Pressure (from Chievres weather station), in mm Hg\n",
    "- RH_out, Humidity outside (from Chievres weather station), in %\n",
    "- Wind speed (from Chievres weather station), in m/s\n",
    "- Visibility (from Chievres weather station), in km\n",
    "- Tdewpoint (from Chievres weather station), in C degrees\n",
    "\n",
    "You are given two datasets: energy_appliances_standard.csv and energy_appliances_extrapolation.csv. The first dataset has typical consumption patterns, while the second one has the top 10% highest consumptions and will be used to test the extrapolating capacities of our models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-exploration",
   "metadata": {},
   "source": [
    "## Task 1: Random Forests (35/100)\n",
    "\n",
    "Random Forests are excellent predictors. Usually we only need to tune one parameter: the number of trees in the model. However, how many trees are enough? Follow these steps:\n",
    "\n",
    "1. Load the training dataset (energy_appliances_standard.csv) and show the descriptive statistics of the variables. (3 pts)\n",
    "\n",
    "2. Create a train / test partition of the data using 30% of the data for the test set and a ```random_state``` value of 20201107(2 pts).\n",
    "\n",
    "3. Follow [this example](https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html) and train a [Random Forest Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) using ```Appliances``` as the target variable. Test between 50 and 250 trees, plotting the Out-of-Bag (OOB) error after every iteration. Be patient as training can take a while. Written answer: What is the optimal number of trees for your model and why do you think this? (15 pts)\n",
    "\n",
    "4. Train your final random forest with the number of trees you selected in part 3. Apply this model over your test set and over the extrapolating dataset (from the file ```energy_appliances_extrapolation.csv```), calculating the mean absolute percentual error for each dataset.  Show in a scatterplot the predicted value vs the real value of the target variable for both the test set and the extrapolation set (in the same plot), differentiating both by using different colors for the points. Written answer: How does the random forest model perform on predicting Appliance energy usage in the extrapolation data set? If it performs poorly, why? If it performs well, why? *Hint: look at the scatterplot*. (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "common-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>...</th>\n",
       "      <th>T8</th>\n",
       "      <th>RH_8</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "      <td>17735.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>68.121229</td>\n",
       "      <td>3.445729</td>\n",
       "      <td>21.688855</td>\n",
       "      <td>40.150264</td>\n",
       "      <td>20.293891</td>\n",
       "      <td>40.469997</td>\n",
       "      <td>22.230926</td>\n",
       "      <td>39.160423</td>\n",
       "      <td>20.860319</td>\n",
       "      <td>38.983631</td>\n",
       "      <td>...</td>\n",
       "      <td>22.050534</td>\n",
       "      <td>43.016242</td>\n",
       "      <td>19.505556</td>\n",
       "      <td>41.552215</td>\n",
       "      <td>7.314032</td>\n",
       "      <td>755.566425</td>\n",
       "      <td>80.249079</td>\n",
       "      <td>3.969812</td>\n",
       "      <td>38.305214</td>\n",
       "      <td>3.762879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.182146</td>\n",
       "      <td>7.552424</td>\n",
       "      <td>1.604312</td>\n",
       "      <td>3.930099</td>\n",
       "      <td>2.171999</td>\n",
       "      <td>4.063088</td>\n",
       "      <td>1.969945</td>\n",
       "      <td>3.219280</td>\n",
       "      <td>2.047586</td>\n",
       "      <td>4.320711</td>\n",
       "      <td>...</td>\n",
       "      <td>1.961083</td>\n",
       "      <td>5.202160</td>\n",
       "      <td>2.010550</td>\n",
       "      <td>4.161873</td>\n",
       "      <td>5.291010</td>\n",
       "      <td>7.339842</td>\n",
       "      <td>14.768037</td>\n",
       "      <td>2.447164</td>\n",
       "      <td>11.957900</td>\n",
       "      <td>4.187098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.790000</td>\n",
       "      <td>27.023333</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>20.463333</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>28.766667</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>27.660000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.306667</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>14.890000</td>\n",
       "      <td>29.166667</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>729.366667</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.760000</td>\n",
       "      <td>37.260000</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>37.930000</td>\n",
       "      <td>20.790000</td>\n",
       "      <td>36.826667</td>\n",
       "      <td>19.566667</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.828889</td>\n",
       "      <td>39.200000</td>\n",
       "      <td>18.066667</td>\n",
       "      <td>38.530000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>751.000000</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>39.533333</td>\n",
       "      <td>19.926667</td>\n",
       "      <td>40.545000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>38.466667</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>38.363333</td>\n",
       "      <td>...</td>\n",
       "      <td>22.166667</td>\n",
       "      <td>42.440000</td>\n",
       "      <td>19.390000</td>\n",
       "      <td>40.863333</td>\n",
       "      <td>6.850000</td>\n",
       "      <td>756.100000</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>42.863333</td>\n",
       "      <td>21.463333</td>\n",
       "      <td>43.326667</td>\n",
       "      <td>23.290000</td>\n",
       "      <td>41.530000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>42.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.390000</td>\n",
       "      <td>46.590000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>44.290000</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>760.950000</td>\n",
       "      <td>91.845238</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>59.633333</td>\n",
       "      <td>29.856667</td>\n",
       "      <td>56.026667</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>49.656667</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.230000</td>\n",
       "      <td>58.780000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>53.326667</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>772.283333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>15.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Appliances        lights            T1          RH_1            T2  \\\n",
       "count  17735.000000  17735.000000  17735.000000  17735.000000  17735.000000   \n",
       "mean      68.121229      3.445729     21.688855     40.150264     20.293891   \n",
       "std       30.182146      7.552424      1.604312      3.930099      2.171999   \n",
       "min       10.000000      0.000000     16.790000     27.023333     16.100000   \n",
       "25%       50.000000      0.000000     20.760000     37.260000     18.790000   \n",
       "50%       60.000000      0.000000     21.600000     39.533333     19.926667   \n",
       "75%       80.000000      0.000000     22.600000     42.863333     21.463333   \n",
       "max      190.000000     50.000000     26.200000     59.633333     29.856667   \n",
       "\n",
       "               RH_2            T3          RH_3            T4          RH_4  \\\n",
       "count  17735.000000  17735.000000  17735.000000  17735.000000  17735.000000   \n",
       "mean      40.469997     22.230926     39.160423     20.860319     38.983631   \n",
       "std        4.063088      1.969945      3.219280      2.047586      4.320711   \n",
       "min       20.463333     17.200000     28.766667     15.100000     27.660000   \n",
       "25%       37.930000     20.790000     36.826667     19.566667     35.500000   \n",
       "50%       40.545000     22.100000     38.466667     20.666667     38.363333   \n",
       "75%       43.326667     23.290000     41.530000     22.100000     42.066667   \n",
       "max       56.026667     29.100000     49.656667     26.200000     51.000000   \n",
       "\n",
       "       ...            T8          RH_8            T9          RH_9  \\\n",
       "count  ...  17735.000000  17735.000000  17735.000000  17735.000000   \n",
       "mean   ...     22.050534     43.016242     19.505556     41.552215   \n",
       "std    ...      1.961083      5.202160      2.010550      4.161873   \n",
       "min    ...     16.306667     29.600000     14.890000     29.166667   \n",
       "25%    ...     20.828889     39.200000     18.066667     38.530000   \n",
       "50%    ...     22.166667     42.440000     19.390000     40.863333   \n",
       "75%    ...     23.390000     46.590000     20.600000     44.290000   \n",
       "max    ...     27.230000     58.780000     24.500000     53.326667   \n",
       "\n",
       "              T_out   Press_mm_hg        RH_out     Windspeed    Visibility  \\\n",
       "count  17735.000000  17735.000000  17735.000000  17735.000000  17735.000000   \n",
       "mean       7.314032    755.566425     80.249079      3.969812     38.305214   \n",
       "std        5.291010      7.339842     14.768037      2.447164     11.957900   \n",
       "min       -5.000000    729.366667     24.000000      0.000000      1.000000   \n",
       "25%        3.500000    751.000000     71.333333      2.000000     29.000000   \n",
       "50%        6.850000    756.100000     84.333333      3.500000     40.000000   \n",
       "75%       10.333333    760.950000     91.845238      5.333333     40.000000   \n",
       "max       26.100000    772.283333    100.000000     14.000000     66.000000   \n",
       "\n",
       "          Tdewpoint  \n",
       "count  17735.000000  \n",
       "mean       3.762879  \n",
       "std        4.187098  \n",
       "min       -6.600000  \n",
       "25%        0.933333  \n",
       "50%        3.433333  \n",
       "75%        6.550000  \n",
       "max       15.500000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data load\n",
    "# Read from the file we just got.\n",
    "energy_data = pd.read_csv('energy_appliances_standard.csv')\n",
    "\n",
    "#Describe\n",
    "energy_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "disturbed-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train / test split\n",
    "# Split into train and test, fixing seed.\n",
    "energy_train_noWoE, energy_test_noWoE = train_test_split(energy_data.iloc[:, 0:], # Data \n",
    "                                                             test_size = 0.3,           # Size of test\n",
    "                                                             random_state = 20201107)   # Seed\n",
    "\n",
    "X = energy_train_noWoE\n",
    "y = energy_train_noWoE.Appliances\n",
    "RANDOM_STATE = 20201107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "excessive-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a binary classification dataset.\n",
    "\n",
    "# NOTE: Setting the `warm_start` construction parameter to `True` disables\n",
    "# support for parallelized ensembles but is necessary for tracking the OOB\n",
    "# error trajectory during training.\n",
    "ensemble_clfs = [\n",
    "    (\"RandomForestClassifier, max_features='sqrt'\",\n",
    "        RandomForestRegressor(warm_start=True, oob_score=True,\n",
    "                               max_features=\"sqrt\",\n",
    "                               random_state=RANDOM_STATE)),\n",
    "    (\"RandomForestClassifier, max_features='log2'\",\n",
    "        RandomForestRegressor(warm_start=True, max_features='log2',\n",
    "                               oob_score=True,\n",
    "                               random_state=RANDOM_STATE)),\n",
    "    (\"RandomForestClassifier, max_features=None\",\n",
    "        RandomForestRegressor(warm_start=True, max_features=None,\n",
    "                               oob_score=True,\n",
    "                               random_state=RANDOM_STATE))\n",
    "]\n",
    "\n",
    "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "min_estimators = 50\n",
    "max_estimators = 250\n",
    "\n",
    "for label, clf in ensemble_clfs:\n",
    "    for i in range(min_estimators, max_estimators + 1):\n",
    "        clf.set_params(n_estimators=i)\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        # Record the OOB error for each `n_estimators=i` setting.\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "        error_rate[label].append((i, oob_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "consistent-adaptation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the OOB error per number of trees\n",
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=label)\n",
    "\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-stephen",
   "metadata": {},
   "source": [
    "**Written answer:** The Optimal Number of Trees is 250 this is because as you increadse the number of trees you reduce your rate of error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "spectacular-radius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5321\n",
      "12414\n"
     ]
    }
   ],
   "source": [
    "# Final forest\n",
    "#Define the classifier\n",
    "energy_rf = RandomForestRegressor(n_estimators=250,random_state=20190305)\n",
    "\n",
    "# Apply this model over your test set and over the extrapolating dataset (from the file energy_appliances_extrapolation.csv),\n",
    "# calculating the mean absolute percentual error for each dataset. \n",
    "\n",
    "# Train the RF.\n",
    "energy_rf.fit(energy_train_noWoE.iloc[:,:-1], \n",
    "               energy_train_noWoE['Appliances'])\n",
    "\n",
    "# Apply the model to the test set.\n",
    "rf_pred_class_test = energy_rf.predict(energy_test_noWoE.iloc[:, :-1])\n",
    "\n",
    "\n",
    "# Calculate error over test set\n",
    "# TestError = mean_absolute_percentage_error(energy_train_noWoE['Appliances'], rf_pred_class_test)\n",
    "\n",
    "# Load the second dataset\n",
    "energy_data2 = pd.read_csv('energy_appliances_extrapolation.csv')\n",
    "energy_train_noWoE2, energy_test_noWoE2 = train_test_split(energy_data.iloc[:, 0:], # Data \n",
    "                                                             test_size = 0.3,           # Size of test\n",
    "                                                             random_state = 20201107)   # Seed\n",
    "energy_rf.fit(energy_train_noWoE2.iloc[:,:-1], \n",
    "               energy_train_noWoE2['Appliances'])\n",
    "\n",
    "rf_pred_class_test2 = energy_rf.predict(energy_test_noWoE2.iloc[:, :-1])\n",
    "\n",
    "print(len(rf_pred_class_test2))\n",
    "print(len(energy_train_noWoE2['Appliances']))\n",
    "\n",
    "# Calculate the error over it\n",
    "# ExtrapolatedError = mean_absolute_percentage_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "comparative-attitude",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TestError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-8a45d87aa0fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Print MAPE over the sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTestError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mExtrapolatedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TestError' is not defined"
     ]
    }
   ],
   "source": [
    "# Print MAPE over the sets\n",
    "print(TestError)\n",
    "print(ExtrapolatedError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "focused-battle",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-cd2773582fd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# the extrapolation set (in the same plot), differentiating both by using different colors for the points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_pred_class_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2888\u001b[0m         \u001b[0mverts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deprecated_parameter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2889\u001b[0m         edgecolors=None, *, plotnonfinite=False, data=None, **kwargs):\n\u001b[1;32m-> 2890\u001b[1;33m     __ret = gca().scatter(\n\u001b[0m\u001b[0;32m   2891\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2892\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m                          \u001b[1;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                 **kwargs)\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4439\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4441\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make the scatterplot\n",
    "# Show in a scatterplot the predicted value vs the real value of the target variable for both the test set and \n",
    "# the extrapolation set (in the same plot), differentiating both by using different colors for the points\n",
    "\n",
    "plt.scatter(rf_pred_class_test,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-parallel",
   "metadata": {},
   "source": [
    "**Written answer: **\n",
    "How does the random forest model perform on predicting Appliance energy usage in the extrapolation data set? If it performs poorly, why? If it performs well, why? \n",
    "\n",
    "The model performs poory because it can't extrapolate the linear trend and accurately predict new examples that have a value higher than the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-hamburg",
   "metadata": {},
   "source": [
    "## Task 2: XGBoosting model (40 pts)\n",
    "\n",
    "Now we'll repeat the process for the XGB model, using an [```XGBRegressor``` object](https://xgboost.readthedocs.io/en/latest/python/python_api.html). The XGBoosting model is much more sensitive to parameter changes though as it allows to tune many different parameters. For this example:\n",
    "\n",
    "1. Written answer: Why do we say we want to use a small learning rate? Why do we say the number of trees to use depends on each dataset/problem? Why do we want to use a small tree depth? (6 pts)\n",
    "\n",
    "2. Selecting a 30% validation sample over the training set, tune your parameters using crossvalidation. Use the following ranges:\n",
    " - Learning rate: [0.01, 0.1, 0.2].\n",
    " - max_depth: 3 to 7.\n",
    " - Number of trees: [350, 400, 450, 500]\n",
    "\n",
    "Leave the other parameters at the values we identified in the lab (except for the objective parameter and those related to classification problems) and use a seed of 20201107. Report the optimal values of your parameters. (20 pts)\n",
    "\n",
    "3. Repeat part 4 of the previous task, but now for your XGB model trained over the optimal parameter combination and the complete training dataset. Plot the variable importance. Written answer: What are the most important variables? Can the XGB model extrapolate? How does it compare to a random forest? (14 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-industry",
   "metadata": {},
   "source": [
    "**Written answer part 1 (2 pts each):**\n",
    "\n",
    "Why do we say we want to use a small learning rate?\n",
    "\n",
    "By using a smaller learning rate it will allow the model to learn a more optimal set of weights but can take much longer to train\n",
    "\n",
    "Why do we say the number of trees to use depends on each dataset/problem?\n",
    "\n",
    "The number of trees is dependant on each dataset/problem because generally more trees you use the better get the results but the improvement decreases as the number of trees increases and thus will take it longer to train which can be very costly for larger datasets.\n",
    "\n",
    "Why do we want to use a small tree depth?\n",
    "\n",
    "We want to use a small tree depth because short trees are very simple and general making binary decisions easy to understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "psychological-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGB model\n",
    "XGB_Energy = XGBRegressor(max_depth=[3,4,5,6,7],                 # Depth of each tree\n",
    "                            learning_rate=[0.01, 0.1, 0.2],            # How much to shrink error in each subsequent training. Trade-off with no. estimators.\n",
    "                            n_estimators=[350, 400, 450, 500],             # How many trees to use, the more the better, but decrease learning rate if many used.\n",
    "                            verbosity=1,                  # If to show more errors or not.\n",
    "                            objective='binary:logistic',  # Type of target variable.\n",
    "                            booster='gbtree',             # What to boost. Trees in this case.\n",
    "                            n_jobs=2,                     # Parallel jobs to run. Set your processor number.\n",
    "                            gamma=0.001,                  # Minimum loss reduction required to make a further partition on a leaf node of the tree. (Controls growth!)\n",
    "                            subsample=1,                  # Subsample ratio. Can set lower\n",
    "                            colsample_bytree=1,           # Subsample ratio of columns when constructing each tree.\n",
    "                            colsample_bylevel=1,          # Subsample ratio of columns when constructing each level. 0.33 is similar to random forest.\n",
    "                            colsample_bynode=1,           # Subsample ratio of columns when constructing each split.\n",
    "                            reg_alpha=1,                  # Regularizer for first fit. alpha = 1, lambda = 0 is LASSO.\n",
    "                            reg_lambda=0,                 # Regularizer for first fit.\n",
    "                            scale_pos_weight=1,           # Balancing of positive and negative weights.\n",
    "                            base_score=0.5,               # Global bias. Set to average of the target rate.\n",
    "                            random_state=20201107,        # Seed\n",
    "                            missing=None                  # How are nulls encoded?\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "simple-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid.\n",
    "param_grid = dict({'n_estimators': [350, 400, 450, 500],\n",
    "                   'max_depth': [3,4,5,6,7],\n",
    "                 'learning_rate' : [0.01, 0.1, 0.2]\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "protective-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reduced validation set.\n",
    "val_train = energy_train_noWoE.sample(frac = 0.3,               # The fraction to extract\n",
    "                                       random_state = 20201107    # The seed.\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "irish-marking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerri\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=1, gamma=0.001,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.01, max_delta_step=None,\n",
       "                                    max_depth=3, min_child_weight=None,\n",
       "                                    missing=None, monotone_constraints=None,\n",
       "                                    n_estimators=350, n_jobs=2,\n",
       "                                    num_parallel_tree=None,\n",
       "                                    objective='binary:logistic',\n",
       "                                    random_state=20201107, reg_alpha=1,\n",
       "                                    reg_lambda=0, scale_pos_weight=1,\n",
       "                                    subsample=1, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 4, 5, 6, 7],\n",
       "                         'n_estimators': [350, 400, 450, 500]},\n",
       "             refit=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train grid search. This takes a while! Go grab a coffee.\n",
    "GridXGB = GridSearchCV(XGB_Energy,        # Original XGB. \n",
    "                       param_grid,          # Parameter grid\n",
    "                       cv = 3,              # Number of cross-validation folds.  \n",
    "                       scoring = 'roc_auc', # How to rank outputs.\n",
    "                       n_jobs = -1,         # Parallel jobs. -1 is \"all you have\"\n",
    "                       refit = False,       # If refit at the end with the best. We'll do it manually.\n",
    "                       verbose = 1          # If to show what it is doing.\n",
    "                      )\n",
    "\n",
    "GridXGB.fit(val_train.iloc[:, :0], val_train['Appliances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "miniature-renewal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 350}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show best params\n",
    "GridXGB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "structured-latitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0.001, gpu_id=None,\n",
      "             importance_type='gain', interaction_constraints=None,\n",
      "             learning_rate=0.01, max_delta_step=None, max_depth=3,\n",
      "             min_child_weight=None, missing=None, monotone_constraints=None,\n",
      "             n_estimators=350, n_jobs=2, num_parallel_tree=None,\n",
      "             objective='binary:logistic', random_state=20201107, reg_alpha=1,\n",
      "             reg_lambda=0, scale_pos_weight=1, subsample=1, tree_method=None,\n",
      "             validate_parameters=None, verbosity=1)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[19:48:02] d:\\bld\\xgboost-split_1615294821523\\work\\src\\objective\\regression_obj.cu:102: label must be in [0,1] for logistic regression",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-5329c43ff7d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXGB_Energy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m XGB_Energy.fit(energy_train_noWoE, \n\u001b[0m\u001b[0;32m     24\u001b[0m                energy_train_noWoE['Appliances'])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    595\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'eval_metric'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         self._Booster = train(params, train_dmatrix,\n\u001b[0m\u001b[0;32m    598\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1280\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [19:48:02] d:\\bld\\xgboost-split_1615294821523\\work\\src\\objective\\regression_obj.cu:102: label must be in [0,1] for logistic regression"
     ]
    }
   ],
   "source": [
    "# Train final XGB with optimal parameters\n",
    "XGB_Energy = XGBRegressor(max_depth=GridXGB.best_params_.get('max_depth'), # Depth of each tree\n",
    "                            learning_rate=GridXGB.best_params_.get('learning_rate'), # How much to shrink error in each subsequent training. Trade-off with no. estimators.\n",
    "                            n_estimators=GridXGB.best_params_.get('n_estimators'), # How many trees to use, the more the better, but decrease learning rate if many used.\n",
    "                            verbosity=1,                  # If to show more errors or not.\n",
    "                            objective='binary:logistic',  # Type of target variable.\n",
    "                            booster='gbtree',             # What to boost. Trees in this case.\n",
    "                            n_jobs=2,                     # Parallel jobs to run. Set your processor number.\n",
    "                            gamma=0.001,                  # Minimum loss reduction required to make a further partition on a leaf node of the tree. (Controls growth!)\n",
    "                            subsample=1,                  # Subsample ratio. Can set lower\n",
    "                            colsample_bytree=1,           # Subsample ratio of columns when constructing each tree.\n",
    "                            colsample_bylevel=1,          # Subsample ratio of columns when constructing each level. 0.33 is similar to random forest.\n",
    "                            colsample_bynode=1,           # Subsample ratio of columns when constructing each split.\n",
    "                            reg_alpha=1,                  # Regularizer for first fit. alpha = 1, lambda = 0 is LASSO.\n",
    "                            reg_lambda=0,                 # Regularizer for first fit.\n",
    "                            scale_pos_weight=1,           # Balancing of positive and negative weights.\n",
    "                            base_score=0.5,               # Global bias. Set to average of the target rate.\n",
    "                            random_state=20201107,        # Seed\n",
    "                            missing=None                  # How are nulls encoded?\n",
    "                            )\n",
    "print(XGB_Energy)\n",
    "\n",
    "XGB_Energy.fit(energy_train_noWoE, \n",
    "               energy_train_noWoE['Appliances'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "alleged-edward",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-8c8093a9fdfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Variable importance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimportances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGB_Energy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfeature_importances_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    739\u001b[0m                 \u001b[1;34m'Feature importance is not defined for Booster type {}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 .format(self.booster))\n\u001b[1;32m--> 741\u001b[1;33m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[0mall_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_Booster'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "# Variable importance\n",
    "importances = XGB_Energy.feature_importances_\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-equity",
   "metadata": {},
   "source": [
    "**Written answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "complimentary-missouri",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make scatterplot\n",
    "# Plot variable importance\n",
    "indices = np.argsort(importances)[::-1] \n",
    "\n",
    "f, ax = plt.subplots(figsize=(3, 8))\n",
    "plt.title(\"Variable Importance - XGB\")\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(y=[energy_train_noWoE.iloc[:, :-1].columns[i] for i in indices], x=importances[indices], \n",
    "            label=\"Total\", color=\"b\")\n",
    "ax.set(ylabel=\"Variable\",\n",
    "       xlabel=\"Variable Importance (Gini)\")\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-japanese",
   "metadata": {},
   "source": [
    "**Written answer: **\n",
    "\n",
    "What are the most important variables? \n",
    "\n",
    "Appliances\n",
    "\n",
    "Can the XGB model extrapolate?\n",
    "\n",
    "XGB are unable to extrapolate values beyond the limits of the training data when making predictions\n",
    "\n",
    "\n",
    "How does it compare to a random forest?\n",
    "\n",
    "Random Forest is a bagging algorithm and it reduces variance. Where as XGB is reducing variance, and also bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-paragraph",
   "metadata": {},
   "source": [
    "## Task 3: Combined model (25 pts)\n",
    "\n",
    "Now we will finally train a model on the combined data, by joining the extrapolation and the original dataset, and study the performance over the original test set, the new test set and the combined result. For this we will only use the Random Forest model. Use a seed of 20201107 for all functions that accept one.\n",
    "\n",
    "1. Create a train / test split set over the extrapolation data, leaving approximately 30% of the data for testing purposes. Combine this train test with the original train set (let's call this the combined train set). (5 pts)\n",
    "2. Train a Random Forest model over the **combined** train data. Discuss how many trees you used and why. (15 pts)\n",
    "3. Plot the variable importance and compare it versus the XGB in task 1. Now that you more data, does the importance change? (5 pts)\n",
    "3. Report the test set performance of your new model over the original test set, the test set you took over the extrapolation dataset and the combined test set. Plot the scatterplot of the both datasets as before in the same plot, differentiating the dataset by using colours. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "durable-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new train and test set.\n",
    "energy_data2 = pd.read_csv('energy_appliances_extrapolation.csv')\n",
    "energy_train_noWoE2, energy_test_noWoE2 = train_test_split(energy_data2.iloc[:, 0:], # Data \n",
    "                                                             test_size = 0.3,           # Size of test\n",
    "                                                             random_state = 20201107)   # Seed\n",
    "\n",
    "energy_train_noWoE3 = pd.concat([energy_train_noWoE2,energy_train_noWoE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "conscious-mattress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=250, random_state=20190305)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the new random forest (tune the trees)\n",
    "energy_rf.fit(energy_train_noWoE3.iloc[:,:-1], \n",
    "               energy_train_noWoE3['Appliances'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-farming",
   "metadata": {},
   "source": [
    "I used the max amount of trees 250 as it will provide better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "lesser-closer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23256362 0.01094707 0.03014076 0.03562594 0.03808642 0.03499622\n",
      " 0.03657935 0.03188335 0.02997547 0.03040019 0.03001392 0.0377552\n",
      " 0.03992402 0.02997361 0.02879361 0.02987146 0.03529347 0.03060506\n",
      " 0.02377523 0.03138812 0.03767062 0.03766982 0.032739   0.03100618\n",
      " 0.03232229]\n",
      "[9.98878800e-01 5.54397135e-04 1.52951339e-05 1.17658972e-05\n",
      " 6.54244482e-06 2.97866384e-05 1.20066585e-05 6.09305532e-06\n",
      " 2.37136802e-05 2.57175955e-06 2.37143022e-06 1.23231484e-04\n",
      " 9.00087557e-05 1.44001524e-05 2.35121061e-06 2.43364386e-05\n",
      " 9.26603775e-06 4.19042081e-06 2.79681736e-06 1.31567387e-05\n",
      " 4.41514956e-05 3.90716030e-05 3.70464588e-05 1.92714402e-05\n",
      " 3.33772369e-05]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ac8659d160>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variable importance\n",
    "importances2 = energy_rf.feature_importances_\n",
    "print(importances)\n",
    "print(importances2)\n",
    "plt.scatter(importances, importances2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-collar",
   "metadata": {},
   "source": [
    "**Written answer: **\n",
    "\n",
    "Now that you more data, does the importance change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print MAPE over the test sets\n",
    "TestSetsError = mean_absolute_percentage_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-parker",
   "metadata": {},
   "source": [
    "**Written answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-offset",
   "metadata": {},
   "source": [
    "What happens now? What can you say about the new model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-dodge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
