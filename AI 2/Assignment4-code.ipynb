{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import seaborn as sn\n",
    "import torchextractor as tx\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from alexnet_pytorch import AlexNet\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset has PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# CIFAR10: 60000 32x32 color images in 6 classes, with 10000 images per class\n",
    "#Downloading training data\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True, num_workers=2)\n",
    "\n",
    "#Downloading test data\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "#Class labels\n",
    "\n",
    "classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n",
    "\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(len(labels))))\n",
    "\n",
    "\n",
    "AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
    "\n",
    "\n",
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds=[]\n",
    "actual=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = AlexNet_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        for k in range(len(outputs)):\n",
    "\n",
    "            probabilities = torch.nn.functional.softmax(outputs[k], dim=0)\n",
    "\n",
    "            top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "\n",
    "            preds.append(categories[top5_catid[0]])\n",
    "            actual.append(classes[labels[k]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = {}\n",
    "for word in preds:\n",
    "    if word in word_counter:\n",
    "        word_counter[word] += 1\n",
    "    else:\n",
    "        word_counter[word] = 1\n",
    "\n",
    "popular_words = sorted(word_counter, key = word_counter.get, reverse = True)\n",
    "\n",
    "top_10 = popular_words[:10]\n",
    "\n",
    "print(top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customMap(i):\n",
    "    switcher={\n",
    "            'moving van':'Airplane',\n",
    "            'fox squirrel':'Car',\n",
    "            'sorrel':'Bird',\n",
    "            'container ship':'Cat',\n",
    "            'English foxhound':'Deer',\n",
    "            'Dandie Dinmont':'Dog',\n",
    "            'thresher':'Frog',\n",
    "            'Japanese spaniel':'Horse',\n",
    "            'milk can':'Ship',\n",
    "            'chain saw':'Truck',\n",
    "         }\n",
    "    return switcher.get(i)\n",
    "\n",
    "y_pred = preds\n",
    "y_true = actual\n",
    "\n",
    "y_predTop = []\n",
    "y_trueTop = []\n",
    "\n",
    "\n",
    "print(len(y_true))\n",
    "print(len(y_pred))\n",
    "\n",
    "for x in range(len(y_pred)):\n",
    "    if (y_pred[x] in top_10):\n",
    "        y_predTop.append(customMap(y_pred[x]))\n",
    "        y_trueTop.append(y_true[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_trueTop, y_predTop, labels=classes)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aylabels = classes \n",
    "axlabels = classes \n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sn.set(font_scale=1.4)  # for label size\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 12}, xticklabels=top_10, yticklabels=aylabels, fmt='g')  # font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
    "\n",
    "fc6_classifier = nn.Sequential(*list(AlexNet_model.classifier.children())[:-5])\n",
    "AlexNet_model.classifier = fc6_classifier\n",
    "\n",
    "AlexNet_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(normalize=True)\n",
    "print(model)\n",
    "\n",
    "xTrain = []\n",
    "yTrain = []\n",
    "\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    if (i<400):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = AlexNet_model(inputs)\n",
    "        out = (outputs.detach().numpy())\n",
    "        for k in range(len(out)):\n",
    "            xTrain.append(out[k])\n",
    "            yTrain.append(labels[k].detach().numpy())\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "clf.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "correctV = 0\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    if (i>=400):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = AlexNet_model(inputs)\n",
    "        out = (outputs.detach().numpy())\n",
    "        pred = clf.predict(out)\n",
    "        for t,k in enumerate(pred,0):\n",
    "            if (k == (labels[t])):\n",
    "                correctV += 1\n",
    "print(correctV/10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "correct = 0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    if (i==i):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = AlexNet_model(inputs)\n",
    "        out = (outputs.detach().numpy())\n",
    "        pred = clf.predict(out)\n",
    "        for t,k in enumerate(pred,0):\n",
    "            if (k == (labels[t])):\n",
    "                correct += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
    "\n",
    "fc7_classifier = nn.Sequential(*list(AlexNet_model.classifier.children())[:-2])\n",
    "AlexNet_model.classifier = fc7_classifier\n",
    "\n",
    "AlexNet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(normalize=True)\n",
    "print(model)\n",
    "\n",
    "xTrain = []\n",
    "yTrain = []\n",
    "\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    if (i<400):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = AlexNet_model(inputs)\n",
    "        out = (outputs.detach().numpy())\n",
    "        for k in range(len(out)):\n",
    "            xTrain.append(out[k])\n",
    "            yTrain.append(labels[k].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "clf.fit(xTrain, yTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "correctV = 0\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    if (i>=400):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = AlexNet_model(inputs)\n",
    "        out = (outputs.detach().numpy())\n",
    "        pred = clf.predict(out)#[0].reshape(1, -1))\n",
    "        for t,k in enumerate(pred,0):\n",
    "            if (k == (labels[t])):\n",
    "                correctV += 1\n",
    "print(correctV/10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "correct = 0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    if (i==i):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = AlexNet_model(inputs)\n",
    "        out = (outputs.detach().numpy())\n",
    "        pred = clf.predict(out)#[0].reshape(1, -1))\n",
    "        for t,k in enumerate(pred,0):\n",
    "            if (k == (labels[t])):\n",
    "                correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct/10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
